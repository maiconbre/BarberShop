import { cacheService } from './CacheService';
import { logger } from '../utils/logger';
import { getAdaptiveConfig, DATA_TYPE_CONFIG } from '../config/apiConfig';
import { requestDebouncer } from '../utils/requestDebouncer';

import { LogConfig } from '../config/logConfig';

// Sistema de logs para requisi√ß√µes da API
class ApiLogger {
  private static requestCounter = 0;

  static logRequest(method: string, endpoint: string, requestId: string, options?: any) {
    if (!LogConfig.shouldLog()) return;
    
    this.requestCounter++;
    const timestamp = new Date().toISOString();
    const logData = {
      requestId,
      method: method.toUpperCase(),
      endpoint,
      timestamp,
      requestNumber: this.requestCounter,
      headers: options?.headers || {},
      body: options?.body ? JSON.parse(options.body) : null
    };
    
    console.group(`üöÄ [API REQUEST #${this.requestCounter}] ${method.toUpperCase()} ${endpoint}`);
    console.log('üìã Request Details:', logData);
    console.log('üïê Timestamp:', timestamp);
    console.log('üîë Request ID:', requestId);
    if (options?.body) {
      console.log('üì¶ Request Body:', JSON.parse(options.body));
    }
    console.groupEnd();
  }

  static logResponse(requestId: string, endpoint: string, status: number, data: any, duration: number) {
    if (!LogConfig.shouldLog()) return;
    
    const timestamp = new Date().toISOString();
    const isSuccess = status >= 200 && status < 300;
    const icon = isSuccess ? '‚úÖ' : '‚ùå';
    
    console.group(`${icon} [API RESPONSE] ${endpoint} - ${status} (${duration}ms)`);
    console.log('üìã Response Details:', {
      requestId,
      endpoint,
      status,
      duration: `${duration}ms`,
      timestamp,
      dataSize: JSON.stringify(data).length + ' bytes'
    });
    console.log('üìä Response Data:', data);
    console.log('‚è±Ô∏è Duration:', `${duration}ms`);
    console.groupEnd();
  }

  static logError(requestId: string, endpoint: string, error: any, duration: number) {
    if (!LogConfig.shouldLog()) return;
    
    const timestamp = new Date().toISOString();
    
    console.group(`üí• [API ERROR] ${endpoint} (${duration}ms)`);
    console.log('üìã Error Details:', {
      requestId,
      endpoint,
      error: error.message || error,
      duration: `${duration}ms`,
      timestamp
    });
    console.error('üö® Error Object:', error);
    console.log('‚è±Ô∏è Duration:', `${duration}ms`);
    console.groupEnd();
  }

  static logCacheHit(endpoint: string, cacheAge: number) {
    if (!LogConfig.shouldLog()) return;
    
    console.log(`üíæ [CACHE HIT] ${endpoint} - Age: ${Math.round(cacheAge/1000)}s`);
  }

  static logCacheMiss(endpoint: string) {
    if (!LogConfig.shouldLog()) return;
    
    console.log(`üîç [CACHE MISS] ${endpoint}`);
  }
}

/**
 * ApiService otimizado com cache inteligente e redu√ß√£o de chamadas desnecess√°rias
 * Resolve problemas de CORS e implementa cache eficiente
 */
class ApiService {
  private static instance: ApiService;
  private readonly config = getAdaptiveConfig();
  private baseUrl: string;
  private isOnline: boolean = navigator.onLine;
  
  // Cache inteligente em mem√≥ria para evitar m√∫ltiplas chamadas
  private memoryCache = new Map<string, { data: any; timestamp: number; ttl: number }>();
  
  // Controle de requisi√ß√µes em andamento para evitar duplica√ß√£o
  private pendingRequests = new Map<string, Promise<any>>();
  private debounceTimers = new Map<string, NodeJS.Timeout>();
  private batchRequests = new Map<string, Promise<any>>();
  private requestCounters = new Map<string, { count: number; timestamp: number }>();
  private connectionErrorTimestamp: number = 0;
  
  // Constantes de configura√ß√£o
  private readonly CACHE_TTL: number = this.config.CACHE_TTL || 300000; // 5 minutos
  private readonly MIN_REQUEST_INTERVAL: number = this.config.MIN_REQUEST_INTERVAL || 2000; // 2 segundos
  private readonly REQUEST_COUNTER_RESET_TIME: number = 60000; // 1 minuto
  private readonly MAX_IDENTICAL_REQUESTS: number = 5; // M√°ximo de requisi√ß√µes id√™nticas em 1 minuto
  
  // M√©tricas simplificadas
  private metrics = {
    totalRequests: 0,
    cacheHits: 0,
    networkRequests: 0
  };
  
  // Sistema de rate limiting inteligente
  private rateLimitInfo = {
    lastRateLimit: 0,
    backoffMultiplier: 1,
    maxBackoff: 60000, // 1 minuto m√°ximo
    baseDelay: 1000 // 1 segundo base
  };

  private constructor() {
    let apiUrl = (import.meta as any).env.VITE_API_URL || '';
    if (apiUrl.endsWith('/')) {
      apiUrl = apiUrl.slice(0, -1);
    }
    this.baseUrl = apiUrl;
    this.setupOnlineListener();
    logger.apiInfo(`ApiService otimizado inicializado com URL: ${this.baseUrl}`);
  }

  static getInstance() {
    if (!ApiService.instance) {
      ApiService.instance = new ApiService();
    }
    return ApiService.instance;
  }

  private setupOnlineListener() {
    window.addEventListener('online', () => {
      this.isOnline = true;
      logger.apiInfo('Conex√£o online detectada');
    });
    
    window.addEventListener('offline', () => {
      this.isOnline = false;
      logger.apiWarn('Conex√£o offline detectada');
    });
  }

  private async fetchWithRetry(url: string, options: RequestInit = {}, attempt: number = 1): Promise<Response> {
    try {
      const response = await fetch(url, options);
      
      // Tratamento espec√≠fico para rate limiting
      if (response.status === 429) {
        this.rateLimitInfo.lastRateLimit = Date.now();
        this.rateLimitInfo.backoffMultiplier = Math.min(
          this.rateLimitInfo.backoffMultiplier * 2, 
          16
        );
        
        if (attempt < this.config.MAX_RETRIES) {
          const retryAfter = response.headers.get('Retry-After');
          const delay = retryAfter ? parseInt(retryAfter) * 1000 : 
            Math.min(
              this.rateLimitInfo.baseDelay * this.rateLimitInfo.backoffMultiplier,
              this.rateLimitInfo.maxBackoff
            );
          
          logger.apiWarn(`Rate limit atingido. Tentando novamente em ${delay}ms (tentativa ${attempt}/${this.config.MAX_RETRIES})`);
          await new Promise(resolve => setTimeout(resolve, delay));
          return this.fetchWithRetry(url, options, attempt + 1);
        }
      }
      
      if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
      
      this.connectionErrorTimestamp = 0;
      return response;
    } catch (error) {
      if (error instanceof TypeError && error.message.includes('fetch')) {
        this.connectionErrorTimestamp = Date.now();
        console.error('Erro de conex√£o detectado, usando cooldown:', error);
      }
      
      if (attempt < this.config.MAX_RETRIES) {
        const backoffTime = this.config.INITIAL_RETRY_DELAY * Math.pow(2, attempt - 1);
        console.log(`Tentativa ${attempt}/${this.config.MAX_RETRIES} falhou. Tentando novamente em ${backoffTime}ms`);
        await new Promise(resolve => setTimeout(resolve, backoffTime));
        return this.fetchWithRetry(url, options, attempt + 1);
      }
      throw error;
    }
  }

  private debounce<T>(key: string, fn: () => Promise<T>, delay: number): Promise<T> {
    if (this.debounceTimers.has(key)) {
      clearTimeout(this.debounceTimers.get(key));
    }

    return new Promise((resolve, reject) => {
      const timer = setTimeout(async () => {
        this.debounceTimers.delete(key);
        try {
          resolve(await fn());
        } catch (error) {
          reject(error);
        }
      }, delay);
      this.debounceTimers.set(key, timer);
    });
  }

  private async batchRequest<T>(endpoint: string, options: RequestInit = {}): Promise<T> {
    const key = `${endpoint}-${JSON.stringify(options)}`;
    
    // Se j√° existe uma requisi√ß√£o em lote para este endpoint, retorna a mesma Promise
    if (this.batchRequests.has(key)) {
      return this.batchRequests.get(key) as Promise<T>;
    }
    
    try {
      // Cria uma nova Promise para a requisi√ß√£o em lote
      const requestPromise = this.executeRequest<T>(endpoint, options);
      
      // Armazena a Promise no mapa de requisi√ß√µes em lote
      this.batchRequests.set(key, requestPromise);
      
      // Aguarda a conclus√£o da requisi√ß√£o
      const data = await requestPromise;
      
      // Remove a requisi√ß√£o do mapa ap√≥s um pequeno delay para permitir que outras requisi√ß√µes a reutilizem
      setTimeout(() => {
        this.batchRequests.delete(key);
      }, 100);
      
      return data;
    } catch (error) {
      // Remove a requisi√ß√£o do mapa em caso de erro
      this.batchRequests.delete(key);
      throw error;
    }
  }
  
  /**
   * Executa uma requisi√ß√£o HTTP com tratamento de erros e retry
   */
  private async executeRequest<T>(endpoint: string, options: RequestInit = {}): Promise<T> {
    const requestId = `req-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    const method = options.method || 'GET';
    const startTime = Date.now();
    
    // Log da requisi√ß√£o
    ApiLogger.logRequest(method, endpoint, requestId, options);
    
    this.metrics.networkRequests++;
    
    try {
      const data = await this.makeRequest<T>(endpoint, options);
      const duration = Date.now() - startTime;
      
      // Log da resposta bem-sucedida
      ApiLogger.logResponse(requestId, endpoint, 200, data, duration);
      
      return data;
    } catch (error) {
      const duration = Date.now() - startTime;
      ApiLogger.logError(requestId, endpoint, error, duration);
      throw error;
    }
  }

  /**
   * Cache inteligente em mem√≥ria - mais r√°pido que localStorage
   */
  private setMemoryCache(key: string, data: any, ttl: number = this.config.CACHE_TTL): void {
    this.memoryCache.set(key, {
      data,
      timestamp: Date.now(),
      ttl
    });
  }

  private getMemoryCache(key: string): any | null {
    const cached = this.memoryCache.get(key);
    if (!cached) return null;
    
    const now = Date.now();
    if (now - cached.timestamp > cached.ttl) {
      this.memoryCache.delete(key);
      return null;
    }
    
    return cached.data;
  }

  /**
   * Requisi√ß√£o otimizada com headers corretos para evitar CORS e rate limiting inteligente
   */
  private async makeRequest<T>(endpoint: string, options: RequestInit = {}): Promise<T> {
    // Verificar se estamos em per√≠odo de rate limit
    const now = Date.now();
    const timeSinceLastRateLimit = now - this.rateLimitInfo.lastRateLimit;
    const currentBackoff = Math.min(
      this.rateLimitInfo.baseDelay * this.rateLimitInfo.backoffMultiplier,
      this.rateLimitInfo.maxBackoff
    );
    
    if (timeSinceLastRateLimit < currentBackoff) {
      const waitTime = currentBackoff - timeSinceLastRateLimit;
      logger.apiWarn(`Rate limit ativo. Aguardando ${waitTime}ms antes da pr√≥xima requisi√ß√£o`);
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }
    
    // Priorizar localStorage para persist√™ncia de 6 horas
    // Usar 'authToken' como chave principal para consist√™ncia
    const token = localStorage.getItem('authToken') || localStorage.getItem('token') || sessionStorage.getItem('authToken') || sessionStorage.getItem('token');
    
    // Headers otimizados - removido x-request-id que causa CORS
    const headers = {
      'Content-Type': 'application/json',
      'Accept': 'application/json',
      ...(token ? { 'Authorization': `Bearer ${token}` } : {}),
      ...options.headers
    };

    try {
      const response = await this.fetchWithRetry(
        `${this.baseUrl}${endpoint}`,
        { ...options, headers, mode: 'cors' }
      );
      
      // Reset do backoff em caso de sucesso
      if (this.rateLimitInfo.backoffMultiplier > 1) {
        this.rateLimitInfo.backoffMultiplier = Math.max(
          this.rateLimitInfo.backoffMultiplier * 0.5,
          1
        );
      }

      const data = await response.json();
      return data;
    } catch (error) {
      // Se for erro 429, atualizar informa√ß√µes de rate limit
      if (error instanceof Error && error.message.includes('429')) {
        this.rateLimitInfo.lastRateLimit = Date.now();
        this.rateLimitInfo.backoffMultiplier = Math.min(
          this.rateLimitInfo.backoffMultiplier * 2, 
          16
        ); // M√°ximo 16x o delay base
        
        logger.apiWarn(`Rate limit detectado. Backoff aumentado para ${this.rateLimitInfo.backoffMultiplier}x`);
      }
      
      throw error;
    }
  }

  /**
   * Verifica se um erro deve ser retentado
   */
  private shouldRetry(error: any): boolean {
    // N√£o tentar novamente para erros de rate limit (j√° tratados separadamente)
    if (error.message && error.message.includes('429')) {
      return false;
    }
    
    // Tentar novamente para erros de rede
    return error instanceof TypeError || 
           (error.message && (
             error.message.includes('fetch') ||
             error.message.includes('network') ||
             error.message.includes('timeout')
           ));
  }

  // M√©todo para verificar e controlar chamadas repetidas
  private checkRepeatedRequests(endpoint: string, method: string = 'GET'): boolean {
    const now = Date.now();
    const requestKey = `${method}-${endpoint}`;
    const requestId = `req-${now}`;
    
    // Verificar contador de chamadas repetidas
    const counterInfo = this.requestCounters.get(requestKey);
    if (counterInfo) {
      // Calcular tempo restante para reset
      const timeElapsed = now - counterInfo.timestamp;
      const timeRemaining = Math.max(0, this.REQUEST_COUNTER_RESET_TIME - timeElapsed);
      const resetInSeconds = Math.ceil(timeRemaining / 1000);
      
      // Resetar contador se passou o tempo de reset
      if (timeElapsed > this.REQUEST_COUNTER_RESET_TIME) {
        this.requestCounters.set(requestKey, { count: 1, timestamp: now });
        console.warn(`[ApiService][${requestId}] Contador de requisi√ß√µes para ${requestKey} resetado ap√≥s ${this.REQUEST_COUNTER_RESET_TIME/1000}s`);
        return false; // N√£o excedeu o limite
      } else {
        // Incrementar contador
        counterInfo.count++;
        this.requestCounters.set(requestKey, counterInfo);
        
        // Verificar se excedeu o limite de chamadas repetidas
        if (counterInfo.count > this.MAX_IDENTICAL_REQUESTS) {
          console.error(`[ApiService][${requestId}] BLOQUEADO: Limite de ${this.MAX_IDENTICAL_REQUESTS} chamadas repetidas excedido para ${requestKey} em ${this.REQUEST_COUNTER_RESET_TIME/1000}s. Contador: ${counterInfo.count}, Reset em ${resetInSeconds}s`);
          return true; // Excedeu o limite
        }
        
        console.warn(`[ApiService][${requestId}] Chamada repetida #${counterInfo.count}/${this.MAX_IDENTICAL_REQUESTS} para ${requestKey} (tempo restante para reset: ${resetInSeconds}s)`);
        return false; // N√£o excedeu o limite
      }
    } else {
      // Inicializar contador
      this.requestCounters.set(requestKey, { count: 1, timestamp: now });
      console.warn(`[ApiService][${requestId}] Primeira chamada para ${requestKey} neste per√≠odo de ${this.REQUEST_COUNTER_RESET_TIME/1000}s`);
      return false; // N√£o excedeu o limite
    }
  }

  async request<T>(endpoint: string, options: RequestInit = {}): Promise<T> {
    const isGetRequest = !options.method || options.method === 'GET';
    const requestKey = `${options.method || 'GET'}-${endpoint}`;
    const requestId = `req-${Date.now()}`;
    
    console.warn(`[ApiService][${requestId}] Requisi√ß√£o ${requestKey} iniciada`);
    
    // Verificar se excedeu o limite de chamadas repetidas para requisi√ß√µes GET
    if (isGetRequest && this.checkRepeatedRequests(endpoint, options.method || 'GET')) {
      // Se excedeu o limite, tenta usar o cache
      const cachedData = cacheService.get<T>(endpoint);
      
      if (cachedData) {
        // Calcular tempo restante para reset do contador
        const counterInfo = this.requestCounters.get(requestKey);
        const timeRemaining = counterInfo ? 
          Math.max(0, this.REQUEST_COUNTER_RESET_TIME - (Date.now() - counterInfo.timestamp)) :
          this.REQUEST_COUNTER_RESET_TIME;
        const resetInSeconds = Math.ceil(timeRemaining / 1000);
        
        console.warn(`[ApiService][${requestId}] Usando cache for√ßado para ${requestKey} devido ao limite de chamadas repetidas. Reset em ${resetInSeconds}s`);
        return cachedData;
      }
      
      // Se n√£o tem cache, lan√ßa um erro com detalhes
      const errorMessage = `Limite de ${this.MAX_IDENTICAL_REQUESTS} chamadas repetidas excedido para ${requestKey} em ${this.REQUEST_COUNTER_RESET_TIME/1000}s. Por favor, aguarde antes de tentar novamente.`;
      console.error(`[ApiService][${requestId}] ${errorMessage}`);
      
      // Criar um objeto de erro com informa√ß√µes adicionais
      const error = new Error(errorMessage);
      (error as any).isRateLimitError = true;
      (error as any).retryAfter = this.REQUEST_COUNTER_RESET_TIME / 1000;
      (error as any).endpoint = endpoint;
      (error as any).requestKey = requestKey;
      (error as any).requestId = requestId;
      throw error;
    }
    
    // Se j√° existe uma requisi√ß√£o em andamento para este endpoint, retorna a mesma Promise
    if (isGetRequest && this.pendingRequests.has(requestKey)) {
      console.log(`[ApiService] Requisi√ß√£o ${requestKey} j√° em andamento, reutilizando Promise`);
      return this.pendingRequests.get(requestKey) as Promise<T>;
    }
    
    if (isGetRequest) {
      const cachedData = cacheService.get<T>(endpoint);
      
      // Verifica se o cache √© v√°lido (o CacheService j√° verifica TTL internamente)
      const isCacheValid = cachedData !== null;
      
      if (isCacheValid) {
        this.metrics.cacheHits++;
        ApiLogger.logCacheHit(endpoint, 0); // Cache age n√£o √© mais rastreado individualmente
        console.log(`[ApiService] Cache v√°lido para ${requestKey}`);
      } else {
        ApiLogger.logCacheMiss(endpoint);
        console.log(`[ApiService] Cache inv√°lido ou inexistente para ${requestKey}`);
      }
      
      // Se estiver offline e tiver cache v√°lido, retorna o cache
      if (!this.isOnline && isCacheValid) {
        console.log(`[ApiService] Offline, usando cache para ${requestKey}`);
        return cachedData;
      }
      
      
      // Se estiver offline e n√£o tiver cache v√°lido, lan√ßa erro
      if (!this.isOnline) {
        console.error(`[ApiService] Offline e sem cache v√°lido para ${requestKey}`);
        throw new Error('Voc√™ est√° offline e n√£o h√° dados em cache v√°lidos dispon√≠veis');
      }
    }

    try {
      console.log(`[ApiService] Criando Promise para requisi√ß√£o ${requestKey}`);
      // Cria uma Promise para a requisi√ß√£o e a armazena no mapa de requisi√ß√µes pendentes
      const requestPromise = isGetRequest ? 
        this.batchRequest<T>(endpoint, options) :
        this.executeRequest<T>(endpoint, options);
      
      // Armazena a Promise no mapa de requisi√ß√µes pendentes para evitar duplica√ß√£o
      if (isGetRequest) {
        console.log(`[ApiService] Armazenando Promise para ${requestKey} no mapa de requisi√ß√µes pendentes`);
        this.pendingRequests.set(requestKey, requestPromise);
      }
      
      // Aguarda a conclus√£o da requisi√ß√£o
      console.log(`[ApiService] Aguardando conclus√£o da requisi√ß√£o ${requestKey}`);
      const data = await requestPromise;
      console.log(`[ApiService] Requisi√ß√£o ${requestKey} conclu√≠da com sucesso`);
      
      // Atualiza o cache se for uma requisi√ß√£o GET
      if (isGetRequest) {
        console.log(`[ApiService] Atualizando cache para ${requestKey}`);
        await cacheService.set(endpoint, data);
        // Remove a requisi√ß√£o do mapa de requisi√ß√µes pendentes
        console.log(`[ApiService] Removendo ${requestKey} do mapa de requisi√ß√µes pendentes`);
        this.pendingRequests.delete(requestKey);
      }
      
      return data;
    } catch (error) {
      console.error(`[ApiService] Erro na requisi√ß√£o ${requestKey}:`, error);
      // Em caso de erro, remove a requisi√ß√£o do mapa de requisi√ß√µes pendentes
      if (isGetRequest) {
        const cachedData = await cacheService.get<T>(endpoint);
        if (cachedData) return cachedData;
      }
      throw error;
    }
  }

  /**
   * Normaliza resposta da API para formato consistente
   */
  private normalizeResponse(data: any, dataType: string = 'dados'): any[] {
    // Se j√° √© um array, retorna diretamente
    if (Array.isArray(data)) {
      return data;
    }

    // Se √© null/undefined, retorna array vazio
    if (data === null || data === undefined) {
      return [];
    }

    // Se tem formato {success: boolean, data: array}
    if (data && typeof data === 'object' && 'data' in data) {
      if (Array.isArray(data.data)) {
        return data.data;
      }
    }

    // Se √© um objeto √∫nico, transforma em array
    if (data && typeof data === 'object') {
      return [data];
    }

    logger.apiWarn(`Formato inesperado para ${dataType}:`, data);
    return [];
  }

  /**
   * M√©todo principal otimizado para requisi√ß√µes GET com cache inteligente
   */
  async get<T>(endpoint: string, options: { ttl?: number; forceRefresh?: boolean } = {}): Promise<T> {
    const cacheKey = `GET-${endpoint}`;
    
    // Criar chave √∫nica para o debounce baseada no endpoint e op√ß√µes
    const requestKey = `get_${endpoint}_${JSON.stringify(options)}`;
    
    return requestDebouncer.execute(requestKey, async () => {
      this.metrics.totalRequests++;

      // Se forceRefresh n√£o est√° ativo, verifica cache
      if (!options.forceRefresh) {
        // 1. Verifica cache em mem√≥ria primeiro (mais r√°pido)
        const memoryData = this.getMemoryCache(cacheKey);
        if (memoryData) {
          this.metrics.cacheHits++;
          logger.apiDebug(`Cache hit (mem√≥ria): ${endpoint}`);
          return memoryData;
        }

        // 2. Verifica cache persistente
        const persistentData = await cacheService.get<T>(endpoint);
        if (persistentData) {
          this.metrics.cacheHits++;
          // Atualiza cache em mem√≥ria para pr√≥ximas consultas
          this.setMemoryCache(cacheKey, persistentData, options.ttl);
          logger.apiDebug(`Cache hit (persistente): ${endpoint}`);
          return persistentData;
        }
      }

      // 3. Verifica se j√° existe requisi√ß√£o em andamento
      if (this.pendingRequests.has(cacheKey)) {
        logger.apiDebug(`Reutilizando requisi√ß√£o em andamento: ${endpoint}`);
        return this.pendingRequests.get(cacheKey) as Promise<T>;
      }

      // 4. Se offline e n√£o tem cache, lan√ßa erro
      if (!this.isOnline) {
        throw new Error('Offline e sem dados em cache dispon√≠veis');
      }

      // 5. Faz nova requisi√ß√£o
      const requestPromise = this.makeRequest<T>(endpoint)
        .then(async (data) => {
          // Salva nos dois caches
          this.setMemoryCache(cacheKey, data, options.ttl);
          await cacheService.set(endpoint, data, { ttl: options.ttl });
          
          logger.apiDebug(`Dados atualizados: ${endpoint}`);
          return data;
        })
        .finally(() => {
          // Remove da lista de requisi√ß√µes pendentes
          this.pendingRequests.delete(cacheKey);
        });

      // Armazena a Promise para evitar requisi√ß√µes duplicadas
      this.pendingRequests.set(cacheKey, requestPromise);
      
      return requestPromise;
    });
  }

  /**
   * M√©todo para requisi√ß√µes POST otimizado
   */
  async post<T>(endpoint: string, data: any): Promise<T> {
    if (!this.isOnline) {
      throw new Error('N√£o √© poss√≠vel enviar dados offline');
    }

    // Para POST, incluir dados no hash para evitar conflitos
    const requestKey = `post_${endpoint}_${JSON.stringify(data)}_${Date.now()}`;
    
    return requestDebouncer.execute(requestKey, async () => {
      const result = await this.makeRequest<T>(endpoint, {
        method: 'POST',
        body: JSON.stringify(data)
      });

      // Invalida caches relacionados ap√≥s POST
      this.invalidateRelatedCaches(endpoint);
      
      return result;
    });
  }

  /**
   * Invalida caches relacionados ap√≥s opera√ß√µes de escrita
   */
  private invalidateRelatedCaches(endpoint: string): void {
    const relatedKeys = Array.from(this.memoryCache.keys())
      .filter(key => {
        // Remove cache de endpoints relacionados
        if (endpoint.includes('appointments')) {
          return key.includes('appointments') || key.includes('barbers');
        }
        if (endpoint.includes('services')) {
          return key.includes('services');
        }
        if (endpoint.includes('comments')) {
          return key.includes('comments');
        }
        return false;
      });

    relatedKeys.forEach(key => {
      this.memoryCache.delete(key);
      logger.apiDebug(`Cache invalidado: ${key}`);
    });
  }

  // M√©todos espec√≠ficos otimizados
  async getApprovedComments() {
    const endpoint = '/api/comments?status=approved';
    try {
      const response = await this.get<any>(endpoint, { 
        ttl: this.config.COMMENTS_CACHE_TTL 
      });
      return this.normalizeResponse(response, 'coment√°rios');
    } catch (error) {
      logger.apiError('Erro ao buscar coment√°rios:', error);
      return [];
    }
  }

  async getBarbers() {
    const endpoint = '/api/barbers';
    try {
      const response = await this.get<any>(endpoint);
      return this.normalizeResponse(response, 'barbeiros');
    } catch (error) {
      logger.apiError('Erro ao buscar barbeiros:', error);
      throw error;
    }
  }

  async getAppointments() {
    const endpoint = '/api/appointments';
    try {
      const response = await this.get<any>(endpoint, {
        ttl: DATA_TYPE_CONFIG.appointments.cacheTTL
      });
      return this.normalizeResponse(response, 'agendamentos');
    } catch (error) {
      logger.apiError('Erro ao buscar agendamentos:', error);
      throw error;
    }
  }

  async getServices() {
    const endpoint = '/api/services';
    try {
      const response = await this.get<any>(endpoint, {
        ttl: this.config.SERVICES_CACHE_DURATION
      });
      return this.normalizeResponse(response, 'servi√ßos');
    } catch (error) {
      logger.apiError('Erro ao buscar servi√ßos:', error);
      throw error;
    }
  }

  /**
   * Submete um novo coment√°rio para aprova√ß√£o
   */
  async submitComment(commentData: { name: string; comment: string }) {
    const endpoint = '/api/comments';
    try {
      const response = await this.post<any>(endpoint, commentData);
      logger.apiInfo('Coment√°rio enviado com sucesso');
      
      // Invalida cache de coment√°rios para for√ßar atualiza√ß√£o
      this.invalidateRelatedCaches('/api/comments');
      
      return response;
    } catch (error) {
      logger.apiError('Erro ao enviar coment√°rio:', error);
      throw error;
    }
  }

  /**
   * Pr√©-carrega dados cr√≠ticos de forma inteligente com suporte a lazy loading
   */
  async preloadCriticalData(): Promise<void> {
    // Verificar se j√° foi executado recentemente para evitar duplica√ß√£o
    const lastPreloadKey = 'lastPreloadTime';
    const lastPreload = localStorage.getItem(lastPreloadKey);
    const now = Date.now();
    
    if (lastPreload && (now - parseInt(lastPreload)) < 60000) {
      logger.apiInfo('Pr√©-carregamento j√° executado recentemente - ignorando');
      return;
    }
    
    // Marcar como executado
    localStorage.setItem(lastPreloadKey, now.toString());
    
    // Mesmo offline, tentamos carregar do cache
    const criticalEndpoints = [
      { endpoint: '/api/services', method: 'getServices', priority: 'high' },
      { endpoint: '/api/barbers', method: 'getBarbers', priority: 'high' }
      // Removido coment√°rios do preload para evitar conflito com Notifications
    ];

    logger.apiInfo('Pr√©-carregando dados cr√≠ticos com lazy loading...');
    
    // Primeiro carrega dados de alta prioridade de forma sequencial
    const highPriorityEndpoints = criticalEndpoints.filter(ep => ep.priority === 'high');
    
    let highPrioritySuccessful = 0;
    for (const { method } of highPriorityEndpoints) {
      try {
        await (this as any)[method]();
        highPrioritySuccessful++;
        // Pequeno delay entre requisi√ß√µes para evitar sobrecarga
        await new Promise(resolve => setTimeout(resolve, 300));
      } catch (error) {
        logger.apiWarn(`Erro no pr√©-carregamento de ${method}:`, error);
      }
    }
    
    logger.apiInfo(`Pr√©-carregamento conclu√≠do: ${highPrioritySuccessful}/${highPriorityEndpoints.length} sucessos`);
  }

  /**
   * Limpa todos os caches
   */
  async clearAllCaches(): Promise<void> {
    this.memoryCache.clear();
    await cacheService.clear();
    logger.apiInfo('Todos os caches foram limpos');
  }

  /**
   * Retorna m√©tricas de uso
   */
  getMetrics() {
    const cacheHitRate = this.metrics.totalRequests > 0 
      ? (this.metrics.cacheHits / this.metrics.totalRequests * 100).toFixed(1)
      : '0';
    
    return {
      ...this.metrics,
      cacheHitRate: `${cacheHitRate}%`,
      memoryCacheSize: this.memoryCache.size
    };
  }
}

export default ApiService.getInstance();

// Exporta m√©tricas para debug
export const getApiMetrics = () => {
  const instance = ApiService.getInstance();
  return instance.getMetrics();
};
